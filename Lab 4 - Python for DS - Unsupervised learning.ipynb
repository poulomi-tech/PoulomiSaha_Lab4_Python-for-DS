{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f26a29",
   "metadata": {
    "id": "83f26a29"
   },
   "source": [
    "# Unsupervised Lab Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea571d1",
   "metadata": {
    "id": "8ea571d1"
   },
   "source": [
    "## Learning outcomes:\n",
    "- Exploratory data analysis and data preparation for model building.\n",
    "- PCA for dimensionality reduction.\n",
    "- K-means and Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f778a",
   "metadata": {
    "id": "fd7f778a"
   },
   "source": [
    "## Problem Statement\n",
    "Based on the given marketing campigan dataset, segment the similar customers into suitable clusters. Analyze the clusters and provide your insights to help the organization promote their business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b58f8f",
   "metadata": {
    "id": "33b58f8f"
   },
   "source": [
    "## Context:\n",
    "- Customer Personality Analysis is a detailed analysis of a company’s ideal customers. It helps a business to better understand its customers and makes it easier for them to modify products according to the specific needs, behaviors and concerns of different types of customers.\n",
    "- Customer personality analysis helps a business to modify its product based on its target customers from different types of customer segments. For example, instead of spending money to market a new product to every customer in the company’s database, a company can analyze which customer segment is most likely to buy the product and then market the product only on that particular segment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867166aa",
   "metadata": {
    "id": "867166aa"
   },
   "source": [
    "## About dataset\n",
    "- Source: https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis?datasetId=1546318&sortBy=voteCount\n",
    "\n",
    "### Attribute Information:\n",
    "- ID: Customer's unique identifier\n",
    "- Year_Birth: Customer's birth year\n",
    "- Education: Customer's education level\n",
    "- Marital_Status: Customer's marital status\n",
    "- Income: Customer's yearly household income\n",
    "- Kidhome: Number of children in customer's household\n",
    "- Teenhome: Number of teenagers in customer's household\n",
    "- Dt_Customer: Date of customer's enrollment with the company\n",
    "- Recency: Number of days since customer's last purchase\n",
    "- Complain: 1 if the customer complained in the last 2 years, 0 otherwise\n",
    "- MntWines: Amount spent on wine in last 2 years\n",
    "- MntFruits: Amount spent on fruits in last 2 years\n",
    "- MntMeatProducts: Amount spent on meat in last 2 years\n",
    "- MntFishProducts: Amount spent on fish in last 2 years\n",
    "- MntSweetProducts: Amount spent on sweets in last 2 years\n",
    "- MntGoldProds: Amount spent on gold in last 2 years\n",
    "- NumDealsPurchases: Number of purchases made with a discount\n",
    "- AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n",
    "- AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n",
    "- AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n",
    "- AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n",
    "- AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n",
    "- Response: 1 if customer accepted the offer in the last campaign, 0 otherwise\n",
    "- NumWebPurchases: Number of purchases made through the company’s website\n",
    "- NumCatalogPurchases: Number of purchases made using a catalogue\n",
    "- NumStorePurchases: Number of purchases made directly in stores\n",
    "- NumWebVisitsMonth: Number of visits to company’s website in the last month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a830406",
   "metadata": {
    "id": "5a830406"
   },
   "source": [
    "### 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65c5528",
   "metadata": {
    "id": "d65c5528"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import zscore\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80eb960",
   "metadata": {
    "id": "c80eb960"
   },
   "source": [
    "### 2. Load the CSV file (i.e marketing.csv) and display the first 5 rows of the dataframe. Check the shape and info of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1caebc10",
   "metadata": {
    "id": "1caebc10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4/9/2012</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8/3/2014</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21-08-2013</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10/2/2014</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19-01-2014</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
       "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
       "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
       "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
       "4  5324        1981         PhD        Married  58293.0        1         0   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  ...  NumCatalogPurchases  NumStorePurchases  \\\n",
       "0    4/9/2012       58       635  ...                   10                  4   \n",
       "1    8/3/2014       38        11  ...                    1                  2   \n",
       "2  21-08-2013       26       426  ...                    2                 10   \n",
       "3   10/2/2014       26        11  ...                    0                  4   \n",
       "4  19-01-2014       94       173  ...                    3                  6   \n",
       "\n",
       "   NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  \\\n",
       "0                  7             0             0             0             0   \n",
       "1                  5             0             0             0             0   \n",
       "2                  4             0             0             0             0   \n",
       "3                  6             0             0             0             0   \n",
       "4                  5             0             0             0             0   \n",
       "\n",
       "   AcceptedCmp2  Complain  Response  \n",
       "0             0         0         1  \n",
       "1             0         0         0  \n",
       "2             0         0         0  \n",
       "3             0         0         0  \n",
       "4             0         0         0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('marketing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9059a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2240, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb7e719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Data columns (total 27 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID                   2240 non-null   int64  \n",
      " 1   Year_Birth           2240 non-null   int64  \n",
      " 2   Education            2240 non-null   object \n",
      " 3   Marital_Status       2240 non-null   object \n",
      " 4   Income               2216 non-null   float64\n",
      " 5   Kidhome              2240 non-null   int64  \n",
      " 6   Teenhome             2240 non-null   int64  \n",
      " 7   Dt_Customer          2240 non-null   object \n",
      " 8   Recency              2240 non-null   int64  \n",
      " 9   MntWines             2240 non-null   int64  \n",
      " 10  MntFruits            2240 non-null   int64  \n",
      " 11  MntMeatProducts      2240 non-null   int64  \n",
      " 12  MntFishProducts      2240 non-null   int64  \n",
      " 13  MntSweetProducts     2240 non-null   int64  \n",
      " 14  MntGoldProds         2240 non-null   int64  \n",
      " 15  NumDealsPurchases    2240 non-null   int64  \n",
      " 16  NumWebPurchases      2240 non-null   int64  \n",
      " 17  NumCatalogPurchases  2240 non-null   int64  \n",
      " 18  NumStorePurchases    2240 non-null   int64  \n",
      " 19  NumWebVisitsMonth    2240 non-null   int64  \n",
      " 20  AcceptedCmp3         2240 non-null   int64  \n",
      " 21  AcceptedCmp4         2240 non-null   int64  \n",
      " 22  AcceptedCmp5         2240 non-null   int64  \n",
      " 23  AcceptedCmp1         2240 non-null   int64  \n",
      " 24  AcceptedCmp2         2240 non-null   int64  \n",
      " 25  Complain             2240 non-null   int64  \n",
      " 26  Response             2240 non-null   int64  \n",
      "dtypes: float64(1), int64(23), object(3)\n",
      "memory usage: 472.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef75724",
   "metadata": {
    "id": "9ef75724"
   },
   "source": [
    "### 3. Check the percentage of missing values? If there is presence of missing values, treat them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c231df",
   "metadata": {
    "id": "f2c231df"
   },
   "outputs": [],
   "source": [
    "df['Income'] = df['Income'].fillna(df['Income'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f3709e",
   "metadata": {
    "id": "86f3709e"
   },
   "source": [
    "### 4. Check if there are any duplicate records in the dataset? If any drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2970671a",
   "metadata": {
    "id": "2970671a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f2b5a",
   "metadata": {
    "id": "3a6f2b5a"
   },
   "source": [
    "### 5. Drop the columns which you think redundant for the analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9ca818b",
   "metadata": {
    "id": "a9ca818b"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID', 'Dt_Customer'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0a112",
   "metadata": {
    "id": "4ff0a112"
   },
   "source": [
    "### 6. Check the unique categories in the column 'Marital_Status'\n",
    "- i) Group categories 'Married', 'Together' as 'relationship'\n",
    "- ii) Group categories 'Divorced', 'Widow', 'Alone', 'YOLO', and 'Absurd' as 'Single'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb1be519",
   "metadata": {
    "id": "eb1be519"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Single', 'Together', 'Married', 'Divorced', 'Widow', 'Alone',\n",
       "       'Absurd', 'YOLO'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Marital_Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d92ec7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Married     864\n",
       "Together    580\n",
       "Single      480\n",
       "Divorced    232\n",
       "Widow        77\n",
       "Alone         3\n",
       "Absurd        2\n",
       "YOLO          2\n",
       "Name: Marital_Status, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Marital_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87ba87da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Single\n",
       "1         Single\n",
       "2       Together\n",
       "3       Together\n",
       "4        Married\n",
       "          ...   \n",
       "2235     Married\n",
       "2236    Together\n",
       "2237    Divorced\n",
       "2238    Together\n",
       "2239     Married\n",
       "Name: Marital_Status, Length: 2240, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Marital_Status'].replace(['Married,Together'],'relationship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1884df9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Single\n",
       "1         Single\n",
       "2       Together\n",
       "3       Together\n",
       "4        Married\n",
       "          ...   \n",
       "2235     Married\n",
       "2236    Together\n",
       "2237      single\n",
       "2238    Together\n",
       "2239     Married\n",
       "Name: Marital_Status, Length: 2240, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Marital_Status'].replace(['Divorced', 'Widow', 'Alone', 'YOLO','Absurd'],'single')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566bfbe",
   "metadata": {
    "id": "9566bfbe"
   },
   "source": [
    "### 7. Group the columns 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', and 'MntGoldProds' as 'Total_Expenses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c3fa800",
   "metadata": {
    "id": "3c3fa800"
   },
   "outputs": [],
   "source": [
    "df[ 'Total_Expenses'] = df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01e27df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1617\n",
       "1         27\n",
       "2        776\n",
       "3         53\n",
       "4        422\n",
       "        ... \n",
       "2235    1341\n",
       "2236     444\n",
       "2237    1241\n",
       "2238     843\n",
       "2239     172\n",
       "Name: Total_Expenses, Length: 2240, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ 'Total_Expenses'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cd083",
   "metadata": {
    "id": "bf0cd083"
   },
   "source": [
    "### 8. Group the columns 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', and 'NumDealsPurchases' as 'Num_Total_Purchases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c535ede",
   "metadata": {
    "id": "9c535ede"
   },
   "outputs": [],
   "source": [
    "df['Num_Total_Purchases'] = df['NumWebPurchases'] +df['NumCatalogPurchases'] + df['NumStorePurchases'] + df['NumDealsPurchases'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54dbd92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       25\n",
       "1        6\n",
       "2       21\n",
       "3        8\n",
       "4       19\n",
       "        ..\n",
       "2235    18\n",
       "2236    22\n",
       "2237    19\n",
       "2238    23\n",
       "2239    11\n",
       "Name: Num_Total_Purchases, Length: 2240, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Num_Total_Purchases'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d2dca5",
   "metadata": {
    "id": "52d2dca5"
   },
   "source": [
    "### 9. Group the columns 'Kidhome' and 'Teenhome' as 'Kids'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7c861a1",
   "metadata": {
    "id": "f7c861a1"
   },
   "outputs": [],
   "source": [
    "df['Kids'] = df['Kidhome'] + df['Teenhome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa07d7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       2\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "2235    1\n",
       "2236    3\n",
       "2237    0\n",
       "2238    1\n",
       "2239    2\n",
       "Name: Kids, Length: 2240, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Kids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f67474",
   "metadata": {
    "id": "36f67474"
   },
   "source": [
    "### 10. Group columns 'AcceptedCmp1 , 2 , 3 , 4, 5' and 'Response' as 'TotalAcceptedCmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc9109f",
   "metadata": {
    "id": "ecc9109f"
   },
   "outputs": [],
   "source": [
    "df['TotalAcceptedCmp'] = df['AcceptedCmp1'] + df['AcceptedCmp2'] + df['AcceptedCmp3']+ df['AcceptedCmp4'] +df['AcceptedCmp5'] +df['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be6d2409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "2235    0\n",
       "2236    1\n",
       "2237    1\n",
       "2238    0\n",
       "2239    1\n",
       "Name: TotalAcceptedCmp, Length: 2240, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TotalAcceptedCmp'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886bfb08",
   "metadata": {
    "id": "886bfb08"
   },
   "source": [
    "### 11. Drop those columns which we have used above for obtaining new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fdfc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853e663",
   "metadata": {
    "id": "e853e663"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4225ced7",
   "metadata": {
    "id": "4225ced7"
   },
   "source": [
    "### 12. Extract 'age' using the column 'Year_Birth' and then drop the column 'Year_birth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d517611e",
   "metadata": {
    "id": "d517611e"
   },
   "outputs": [],
   "source": [
    "df['Age'] = 2024 - df['Year_Birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fd28647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       67\n",
       "1       70\n",
       "2       59\n",
       "3       40\n",
       "4       43\n",
       "        ..\n",
       "2235    57\n",
       "2236    78\n",
       "2237    43\n",
       "2238    68\n",
       "2239    70\n",
       "Name: Age, Length: 2240, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3c92d",
   "metadata": {
    "id": "f2d3c92d"
   },
   "source": [
    "### 13. Encode the categorical variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "030cfc32",
   "metadata": {
    "id": "030cfc32"
   },
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a90cdddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.fillna(df_encoded.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242e36d",
   "metadata": {
    "id": "9242e36d"
   },
   "source": [
    "### 14. Standardize the columns, so that values are in a particular range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72475b68",
   "metadata": {
    "id": "72475b68"
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2347f627",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Graduation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scaled_features \u001b[38;5;241m=\u001b[39m \u001b[43mStandardScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m    860\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 861\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 546\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    547\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Graduation'"
     ]
    }
   ],
   "source": [
    "scaled_features = StandardScaler().fit_transform(df1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a22a3d9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scaled_features_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mscaled_features\u001b[49m, index\u001b[38;5;241m=\u001b[39mdf1\u001b[38;5;241m.\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mdf1\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaled_features' is not defined"
     ]
    }
   ],
   "source": [
    "scaled_features_df = pd.DataFrame(scaled_features, index=df1.index, columns=df1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d063d2e2",
   "metadata": {
    "id": "d063d2e2"
   },
   "source": [
    "### 15. Apply PCA on the above dataset and determine the number of PCA components to be used so that 90-95% of the variance in data is explained by the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6df3c70e",
   "metadata": {
    "id": "6df3c70e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cov_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcov(\u001b[43mscaled_features\u001b[49m\u001b[38;5;241m.\u001b[39mT)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaled_features' is not defined"
     ]
    }
   ],
   "source": [
    "cov_matrix = np.cov(scaled_features.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df19d7",
   "metadata": {
    "id": "b2df19d7"
   },
   "source": [
    "### 16. Apply K-means clustering and segment the data (Use PCA transformed data for clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8bb4c",
   "metadata": {
    "id": "a3a8bb4c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8463aed",
   "metadata": {
    "id": "d8463aed"
   },
   "source": [
    "### 17. Apply Agglomerative clustering and segment the data (Use Original data for clustering), and perform cluster analysis by doing bivariate analysis between the cluster label and different features and write your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca165b",
   "metadata": {
    "id": "b5ca165b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797a5ecd",
   "metadata": {
    "id": "797a5ecd"
   },
   "source": [
    "### Visualization and Interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e75760",
   "metadata": {
    "id": "d1e75760"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36afd95b",
   "metadata": {
    "id": "36afd95b"
   },
   "source": [
    "-----\n",
    "## Happy Learning\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "36afd95b"
   ],
   "name": "Unsupervised Learning - Lab session.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
